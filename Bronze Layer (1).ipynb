{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "045bc811-d80e-4373-8386-69cee8f631db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef3b36e1-bf8a-472f-a27d-8b46e1865760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DecimalType, LongType\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, to_date, monotonically_increasing_id\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dae03774-e046-41ae-a701-062327178e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialize SparkSession with Blob credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb5c155-e82d-43d8-a8dc-53a363fd324f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tenant_id = dbutils.secrets.get(scope=\"databricks scope\", key=\"tenant-id\")\n",
    "client_id = dbutils.secrets.get(scope=\"databricks scope\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"databricks scope\", key=\"client-secret\")\n",
    "spark = SparkSession.builder.appName(\"Bronze Batch Ingestion\") \\\n",
    "    .config(\"fs.azure.account.auth.type.demotri.dfs.core.windows.net\", \"OAuth\") \\\n",
    "    .config(\"fs.azure.account.oauth.provider.type.demotri.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\") \\\n",
    "    .config(\"fs.azure.account.oauth2.client.id.demotri.dfs.core.windows.net\",client_id) \\\n",
    "    .config(\"fs.azure.account.oauth2.client.secret.demotri.dfs.core.windows.net\",client_secret) \\\n",
    "    .config(\"fs.azure.account.oauth2.client.endpoint.demotri.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c770b8f-289f-4651-9ad6-926490b49e50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## JDBC Azure SQL config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821e301b-4960-4afc-b3f6-51eecf10ff8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db_user = dbutils.secrets.get(scope=\"databricks scope\", key=\"db-user\")\n",
    "db_password = dbutils.secrets.get(scope=\"databricks scope\", key=\"db-password\")\n",
    "\n",
    "jdbc_url = (\n",
    "    \"jdbc:sqlserver://testsecondserver.database.windows.net:1433;\"\n",
    "    \"databaseName=testNewdb;\"\n",
    "    \"encrypt=true;\"\n",
    "    \"trustServerCertificate=false;\"\n",
    "    \"hostNameInCertificate=*.database.windows.net;\"\n",
    "    \"loginTimeout=30;\"\n",
    ")\n",
    "connection_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fdae867-06a9-4c9c-a851-208a25e0c536",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9834ee-2ebd-421e-9c23-624b8f6ac13c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jdbc_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"dbo.jdbc_data\",\n",
    "    properties=connection_properties\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a93be7-b92b-40e2-a90c-4932a39d79f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Blob CSV (uploaded as blob_storage_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b97e2f-3b76-4394-9ae3-e4d15edc801e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_key = dbutils.secrets.get(scope=\"databricks scope\", key=\"demotri-key\")\n",
    "\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.demotri.dfs.core.windows.net\",\n",
    "    storage_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864c868b-145f-462e-8b1b-fe5b07d48f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "blob_path = \"abfss://data@demotri.dfs.core.windows.net/blob_storage_data.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").csv(blob_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c9cdc0b-569d-4ec9-b42e-565586b29696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Join Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb2c1be9-4271-4248-a4c8-3299937182f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined Count: 1000\nroot\n |-- Customer_ID: string (nullable = true)\n |-- Age: string (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Annual_Income: string (nullable = true)\n |-- Satisfaction_Score: string (nullable = true)\n |-- Email_Opt_In: string (nullable = true)\n |-- Target_Churn: string (nullable = true)\n |-- Total_Spend: string (nullable = true)\n |-- Years_as_Customer: string (nullable = true)\n |-- Num_of_Purchases: string (nullable = true)\n |-- Average_Transaction_Amount: string (nullable = true)\n |-- Num_of_Returns: string (nullable = true)\n |-- Num_of_Support_Contacts: string (nullable = true)\n |-- Last_Purchase_Days_Ago: string (nullable = true)\n |-- Promotion_Response: string (nullable = true)\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[Customer_ID: string, Age: string, Gender: string, Annual_Income: string, Satisfaction_Score: string, Email_Opt_In: string, Target_Churn: string, Total_Spend: string, Years_as_Customer: string, Num_of_Purchases: string, Average_Transaction_Amount: string, Num_of_Returns: string, Num_of_Support_Contacts: string, Last_Purchase_Days_Ago: string, Promotion_Response: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform INNER JOIN on 'customer_id'\n",
    "joined_df = jdbc_df.alias(\"j\").join(df.alias(\"b\"), on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Show number of joined records\n",
    "print(\"Joined Count:\", joined_df.count())\n",
    "\n",
    "# Show schema of the resulting DataFrame\n",
    "joined_df.printSchema()\n",
    "\n",
    "# Display top 10 records (Databricks-specific)\n",
    "joined_df.orderBy(\"customer_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6beb0881-af34-4235-b1c8-66f7293e1766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create a schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be4cdbe5-16c1-4293-873d-7923a7b2451f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a schema if not exists\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS rawdata.Bronze_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d49288d1-95c2-4875-92f3-1443443d680e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze ingestion completed successfully for 2025-12-26\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Add the ingest_date column to the DataFrame\n",
    "new_df = joined_df.withColumn(\"ingest_date\", current_date())\n",
    "\n",
    "# Optional: Enable dynamic partition overwrite to avoid replacing the whole table\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "\n",
    "# Write to Delta table with partitioning\n",
    "new_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"ingest_date\") \\\n",
    "     \\\n",
    "    .saveAsTable(\"rawdata.bronze_layer.rawfile\") \n",
    "\n",
    "# Confirmation message\n",
    "print(f\"Bronze ingestion completed successfully for {datetime.now(timezone.utc).strftime('%Y-%m-%d')}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}